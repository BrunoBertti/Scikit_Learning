########## 1.7.3. Classificação de Processo Gaussiana (GPC) ##########


    # O GaussianProcessClassifier implementa processos Gaussianos (GP) para fins de classificação, mais especificamente para classificação probabilística, onde as previsões de teste assumem a forma de probabilidades de classe. GaussianProcessClassifier coloca um GP antes de uma função latente f, que é então esmagada através de uma função de ligação para obter a classificação probabilística. A função latente f é a chamada função de incômodo, cujos valores não são observados e não são relevantes por si mesmos. Seu objetivo é permitir uma formulação conveniente do modelo, e f é removido (integrado) durante a previsão. GaussianProcessClassifier implementa a função de ligação logística, para a qual a integral não pode ser calculada analiticamente, mas é facilmente aproximada no caso binário.

    # Em contraste com a configuração de regressão, a posterior da função latente f não é gaussiana mesmo para um GP anterior, uma vez que uma probabilidade gaussiana é inadequada para rótulos de classe discreta. Em vez disso, uma verossimilhança não gaussiana correspondente à função de ligação logística (logit) é usada. GaussianProcessClassifier aproxima a posterior não-Gaussiana com uma Gaussiana baseada na aproximação de Laplace. Mais detalhes podem ser encontrados no Capítulo 3 de [RW2006].

    # A média anterior de GP é assumida como zero. A covariância do prior é especificada passando um objeto kernel. Os hiperparâmetros do kernel são otimizados durante o ajuste de GaussianProcessRegressor, maximizando a probabilidade de log-marginal (LML) com base no otimizador passado. Como o LML pode ter vários ótimos locais, o otimizador pode ser iniciado repetidamente especificando n_restarts_optimizer. A primeira execução é sempre realizada a partir dos valores iniciais dos hiperparâmetros do kernel; execuções subsequentes são realizadas a partir de valores de hiperparâmetros que foram escolhidos aleatoriamente a partir do intervalo de valores permitidos. Se os hiperparâmetros iniciais devem ser mantidos fixos, Nenhum pode ser passado como otimizador.

    # O GaussianProcessClassifier suporta classificação multiclasse realizando treinamento e previsão baseado em um contra descanso ou um contra um. No one-versus-rest, um classificador de processo gaussiano binário é ajustado para cada classe, que é treinada para separar essa classe das demais. Em “one_vs_one”, um classificador binário de processo Gaussiano é ajustado para cada par de classes, que é treinado para separar essas duas classes. As previsões desses preditores binários são combinadas em previsões multiclasse. Consulte a seção sobre classificação multiclasse para obter mais detalhes.

    # No caso da classificação de processos gaussiana, “one_vs_one” pode ser computacionalmente mais barato, pois tem que resolver muitos problemas envolvendo apenas um subconjunto de todo o conjunto de treinamento, em vez de menos problemas em todo o conjunto de dados. Como a classificação do processo gaussiano é dimensionada cúbica com o tamanho do conjunto de dados, isso pode ser consideravelmente mais rápido. No entanto, observe que “one_vs_one” não suporta estimativas de probabilidade de previsão, mas apenas previsões simples. Além disso, observe que o GaussianProcessClassifier (ainda) não implementa uma verdadeira aproximação de Laplace multiclasse internamente, mas, como discutido acima, é baseado na resolução de várias tarefas de classificação binária internamente, que são combinadas usando um contra resto ou um contra um. 