########## 1.16.1. Curvas de calibração ##########


    # As curvas de calibração (também conhecidas como diagramas de confiabilidade) comparam o quão bem as previsões probabilísticas de um classificador binário são calibradas. Ele representa graficamente a frequência real do rótulo positivo em comparação com sua probabilidade prevista, para previsões binadas. O eixo x representa a probabilidade média prevista em cada compartimento. O eixo y é a fração de positivos, ou seja, a proporção de amostras cuja classe é a classe positiva (em cada compartimento). O gráfico da curva de calibração superior é criado com CalibrationDisplay.from_estimators, que usa calibração_curve para calcular as probabilidades médias previstas por compartimento e a fração de positivos. CalibrationDisplay.from_estimator toma como entrada um classificador ajustado, que é usado para calcular as probabilidades previstas. O classificador, portanto, deve ter o método predict_proba. Para os poucos classificadores que não têm um método predict_proba, é possível usar CalibratedClassifierCV para calibrar as saídas do classificador para probabilidades.

    # O histograma inferior fornece algumas dicas sobre o comportamento de cada classificador, mostrando o número de amostras em cada categoria de probabilidade prevista. 


        # https://scikit-learn.org/stable/auto_examples/calibration/plot_compare_calibration.html


    # LogisticRegression retorna previsões bem calibradas por padrão, pois otimiza diretamente a perda de log. Em contraste, os outros métodos retornam probabilidades tendenciosas; com diferentes vieses por método:

    # GaussianNB tende a empurrar as probabilidades para 0 ou 1 (observe as contagens nos histogramas). Isso ocorre principalmente porque ele pressupõe que os recursos são condicionalmente independentes, dada a classe, o que não é o caso neste conjunto de dados que contém 2 recursos redundantes.

    # RandomForestClassifier mostra o comportamento oposto: os histogramas mostram picos em aproximadamente 0,2 e 0,9 probabilidade, enquanto probabilidades próximas a 0 ou 1 são muito raras. Uma explicação para isso é dada por Niculescu-Mizil e Caruana 1: “Métodos como ensacamento e florestas aleatórias que calculam a média de previsões de um conjunto base de modelos podem ter dificuldade em fazer previsões próximas de 0 e 1 porque a variância nos modelos básicos subjacentes distorcerá as previsões que deve estar próximo de zero ou um de distância desses valores. Como as previsões são restritas ao intervalo [0,1], os erros causados ​​pela variância tendem a ser unilaterais próximos a zero e um. Por exemplo, se um modelo deve prever p = 0 para um caso, a única maneira de o ensacamento conseguir isso é se todas as árvores ensacadas predizerem zero. Se adicionarmos ruído às árvores sobre as quais o ensacamento está fazendo a média, esse ruído fará com que algumas árvores prevejam valores maiores do que 0 para este caso, afastando assim a previsão média do conjunto ensacado de 0. Observamos este efeito mais fortemente com aleatório florestas porque as árvores de nível básico treinadas com florestas aleatórias têm uma variação relativamente alta devido ao subconjunto de recursos ”. Como resultado, a curva de calibração também conhecida como diagrama de confiabilidade (Wilks 1995 2) mostra uma forma sigmóide característica, indicando que o classificador poderia confiar mais em sua “intuição” e retornar probabilidades mais próximas de 0 ou 1 normalmente.

    # A classificação de vetores de suporte linear (LinearSVC) mostra uma curva ainda mais sigmóide do que RandomForestClassifier, o que é típico para métodos de margem máxima (compare Niculescu-Mizil e Caruana 1), que se concentram em amostras difíceis de classificar que estão perto do limite de decisão (o vetores de suporte). 